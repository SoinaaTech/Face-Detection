{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TP3 Face détection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ousse\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage import feature \n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import numpy as np\n",
    "import mtcnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection function\n",
    "def detect_faces(image):\n",
    "    detector = mtcnn.MTCNN()\n",
    "    faces = detector.detect_faces(image)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract LBP features\n",
    "def extract_lbp(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = feature.local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "# Function to extract HOG features\n",
    "def extract_hog(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (64, 64))  # Standardize size\n",
    "    \n",
    "    hog_features = feature.hog(resized, \n",
    "                      orientations=9,\n",
    "                      pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2),\n",
    "                      block_norm='L2-Hys',\n",
    "                      feature_vector=True)\n",
    "    \n",
    "    return hog_features\n",
    "\n",
    "# Function to extract pooled SIFT features\n",
    "def extract_sift_pooled(image, pooling='mean'):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is None:\n",
    "        return None  # Return None if no descriptors found\n",
    "    \n",
    "    # Pool descriptors into a fixed-size vector\n",
    "    if pooling == 'mean':\n",
    "        pooled_feature = np.mean(descriptors, axis=0)\n",
    "    elif pooling == 'max':\n",
    "        pooled_feature = np.max(descriptors, axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Pooling method not supported. Use 'mean' or 'max'.\")\n",
    "    \n",
    "    return pooled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features depending on the method\n",
    "def extract_features(image, method):\n",
    "    faces = detect_faces(image)\n",
    "    if faces:\n",
    "        # Assume the first detected face is the target\n",
    "        x, y, width, height = faces[0]['box']\n",
    "        face_region = image[y:y+height, x:x+width]\n",
    "        \n",
    "        if method == \"lbp\":\n",
    "            feature = extract_lbp(face_region)\n",
    "        elif method == \"hog\":\n",
    "            feature = extract_hog(face_region)\n",
    "        elif method == \"sift\":\n",
    "            feature = extract_sift_pooled(face_region)  # Use pooled SIFT extraction\n",
    "    else:\n",
    "        # If no face detected, return None\n",
    "        feature = None\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the SVM model\n",
    "def train_svm(features, labels):\n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(features, labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader_FeatuerExtract(path, method):\n",
    "    profiles = os.listdir(path=path)\n",
    "    features = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    profiles_names = []\n",
    "\n",
    "    for profi in profiles:\n",
    "        profiles_names.append(profi)\n",
    "        prof_path = os.path.join(path, profi) + \"/\"\n",
    "        for img in os.listdir(prof_path):\n",
    "            image_path = os.path.join(prof_path, img)\n",
    "            image = cv2.imread(image_path)\n",
    "            image_feature = extract_features(image, method)  \n",
    "            \n",
    "            if image_feature is not None: \n",
    "                features.append(image_feature)\n",
    "                labels.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les poids du SVM basé sur lbp sont bien sauvegardés .... OK!\n",
      "Les poids du SVM basé sur sift sont bien sauvegardés .... OK!\n",
      "Les poids du SVM basé sur hog sont bien sauvegardés .... OK!\n"
     ]
    }
   ],
   "source": [
    "path = \"./image_faciale_IM/\"\n",
    "Method = [\"lbp\", \"sift\", \"hog\"]\n",
    "for method in Method:\n",
    "    features, labels = DataLoader_FeatuerExtract(path, method)\n",
    "    if len(np.unique(labels)) > 1:  # Vérifiez qu'il y a plus d'une classe\n",
    "        model = train_svm(features, labels)\n",
    "        joblib.dump(model, f\"./Modele_tp3/face_recognition_model_{method}.pkl\")\n",
    "        print(f\"Les poids du SVM basé sur {method} sont bien sauvegardés .... OK!\")\n",
    "    else:\n",
    "        print(f\"Attention : Le modèle {method} n'a qu'une seule classe. Vérifiez vos données.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "path = \"./image_faciale_IM/\"\n",
    "Method = [\"lbp\", \"sift\", \"hog\"]\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Liste pour stocker les caractéristiques et les étiquettes\n",
    "features = []\n",
    "labels = []\n",
    "name = os.listdir(path)\n",
    "method = Method[2]  \n",
    "# Charger le modèle sauvegardé correspondant à la méthode choisie\n",
    "model_path = f\"./Modele_tp3/face_recognition_model_{method}.pkl\"\n",
    "model = joblib.load(model_path)\n",
    "# Boucle de traitement de la vidéo\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Détecter les visages\n",
    "    faces = detect_faces(frame)\n",
    "    for face in faces:\n",
    "        x, y, width, height = face['box']\n",
    "        detected_face = frame[y:y+height, x:x+width]\n",
    "\n",
    "        # Extraire les caractéristiques du visage détecté\n",
    "        if method == 'lbp':\n",
    "            face_features = extract_lbp(detected_face)\n",
    "        elif method == 'hog':\n",
    "            face_features = extract_hog(detected_face)\n",
    "        else:\n",
    "            face_features = extract_sift_pooled(detected_face)\n",
    "        # Vérifier si les caractéristiques ont été extraites avec succès\n",
    "        if face_features is not None:\n",
    "            # Prédiction avec le modèle SVM\n",
    "            prediction = model.predict([face_features])\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name[prediction[0]], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Détection et Reconnaissance de Visage\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
